[config]
batch_size = 60
train_resolution = 224
;inference_resolution = 512
test_batch_size = 1
test_interval = 1
validation_split = 10
epochs = 40
lr = 5e-4
end_lr = 1e-4
beta1 = 0.5
beta2 = 0.99
weight_decay = 5e-4
;momentum = 0.5
seed = 1
log_interval = 10
optimizer = Adam
model = simpleconv
pretrained = yes
weight_classes = yes

[augmentation]
vertical_flip_prob = 0.5
rotation = 30
;translate = 0.0
scale = 0.15
shear = 10
noise_std = 0.05
noise_prob = 0.5