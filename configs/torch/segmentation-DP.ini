[config]
batch_size = 32
train_resolution = 240
;inference_resolution = 512
test_batch_size = 128
test_interval = 1
validation_split = 10 
epochs = 50
lr = 1e-3
end_lr = 1e-4
restarts = 1
beta1 = 0.9
beta2 = 0.999
weight_decay = 1e-3
;momentum = 0.5
deterministic = yes
seed = 1
log_interval = 10
optimizer = Adam
;differentially_private = no
dp_stats_exchange = no
dpsse_epsilon = 1.0
model = MoNet
;not used
pretrained = no 
weight_classes = no
pooling_type = max

;not used
[augmentation] 
rotation = 0
translate = 0.0
scale = 0.0
shear = 0
mixup = no
mixup_prob = 0.0

;not used
[albumentations] 
clahe = no
overall_prob = 0.
individual_probs = 0.
noise_std = 0.05
noise_prob = 0.
randomgamma = no
randombrightness = no
blur = no
elastic = no   
optical_distortion = no
grid_distortion = no
grid_shuffle = no
hsv = no
invert = no
cutout = no
shadow = no
fog = no
sun_flare = no
solarize = no
equalize = no
grid_dropout = no

;not used
[federated] 
sync_every_n_batch = 40
wait_interval = 0.1
keep_optim_dict = no
repetitions_dataset = 1
weighted_averaging = no
;precision_fractional=16

[system]
num_threads = 1

[DP]
differentially_private = no
noise_multiplier = 0.01
max_grad_norm = 10.
target_delta = 1e-5