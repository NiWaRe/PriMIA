{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Start Here About PriMIA is a framework for end-to-end privacy preserving machine learning on medical images designed and built at the Technical University of Munich, OpenMined and Imperial College London. It enables you to do federated training of convolutional neural networks and encrypted inference from a simple command-line interface. Use Cases PriMIA is designed with flexibility and accessibility in mind. It's suitable for beginners just starting out their experimentation with privacy preserving machine learning and can scale up to decentralised cloud instance training on real-life medical datasets. We incorporate current state-of-the-art privacy preservation methods from PySyft and extend them with functionality tailored to medical images. How to get started To train a model on a real-life medical dataset, just clone the repository, install the dependencies (documentation here ) and run: 1 2 3 4 make symbolic_server_folders python train.py --config configs/torch/pneumonia-resnet-pretrained.ini --train_federated --data_dir data/server_simulation PriMIA will train a ResNet18 using federated learning on PySyft VirtualWorkers and return the model weights and metrics in model_weights . Then just run: 1 2 python inference.py --model_weights <path/to/weights.pt> --encrypted_inference --data_dir <path/to/test_images> And PriMIA will return end-to-end encrypted predictions on the test set using Function Secret Sharing ! We also provide many more options, such as other models, working with MNIST for weaker machines, turning on and off various privacy-enhancing technologies, hyperparameter search for the whole federation and a gamut of choices, all easy to implement via a single .ini file. To have a look at some more recipes, go to this page ! Team PriMIA is built by a diverse team of academics, open source contributors and industry researchers. Our core team consists of: Georgios Kaissis ( Project Lead ), PostDoc at TUM and ICL, OpenMined Research Scientist Alex Ziller ( Lead Developer ), PhD student at TUM, OpenMined Research Scientist Jonathan Passerat Palmbach ( Security Lead ), PostDoc at ICL, Director of Cryptography at Consensys Health Rickmer Braren ( Medical Lead ), Professor of Radiology at TUM Th\u00e9o Ryffel, PhD student at INRIA, OpenMined Cryptography lead, CTO at Arkhn Andrew Trask, PhD student at University of Oxford, OpenMined project leader ... and many others from the Technical University of Munich, Imperial College London, INRIA, University of Oxford, OpenMined, Facebook Research, Consensys Health and Arkhn. Publication This is the companion repository to our publication (xxx). Dataset We used the Paediatric Pneumonia Dataset originally created by Kermany et al. For details, see this page . Disclaimer This software is a research product and is provided as is without any guarantees of functionality, security, support or compatibility. Until appropriately validated, it must not be used in any critical workflow and we assume no liability for any user action or omission.","title":"Start Here"},{"location":"#start-here","text":"","title":"Start Here"},{"location":"#about","text":"PriMIA is a framework for end-to-end privacy preserving machine learning on medical images designed and built at the Technical University of Munich, OpenMined and Imperial College London. It enables you to do federated training of convolutional neural networks and encrypted inference from a simple command-line interface.","title":"About"},{"location":"#use-cases","text":"PriMIA is designed with flexibility and accessibility in mind. It's suitable for beginners just starting out their experimentation with privacy preserving machine learning and can scale up to decentralised cloud instance training on real-life medical datasets. We incorporate current state-of-the-art privacy preservation methods from PySyft and extend them with functionality tailored to medical images.","title":"Use Cases"},{"location":"#how-to-get-started","text":"To train a model on a real-life medical dataset, just clone the repository, install the dependencies (documentation here ) and run: 1 2 3 4 make symbolic_server_folders python train.py --config configs/torch/pneumonia-resnet-pretrained.ini --train_federated --data_dir data/server_simulation PriMIA will train a ResNet18 using federated learning on PySyft VirtualWorkers and return the model weights and metrics in model_weights . Then just run: 1 2 python inference.py --model_weights <path/to/weights.pt> --encrypted_inference --data_dir <path/to/test_images> And PriMIA will return end-to-end encrypted predictions on the test set using Function Secret Sharing ! We also provide many more options, such as other models, working with MNIST for weaker machines, turning on and off various privacy-enhancing technologies, hyperparameter search for the whole federation and a gamut of choices, all easy to implement via a single .ini file. To have a look at some more recipes, go to this page !","title":"How to get started"},{"location":"#team","text":"PriMIA is built by a diverse team of academics, open source contributors and industry researchers. Our core team consists of: Georgios Kaissis ( Project Lead ), PostDoc at TUM and ICL, OpenMined Research Scientist Alex Ziller ( Lead Developer ), PhD student at TUM, OpenMined Research Scientist Jonathan Passerat Palmbach ( Security Lead ), PostDoc at ICL, Director of Cryptography at Consensys Health Rickmer Braren ( Medical Lead ), Professor of Radiology at TUM Th\u00e9o Ryffel, PhD student at INRIA, OpenMined Cryptography lead, CTO at Arkhn Andrew Trask, PhD student at University of Oxford, OpenMined project leader ... and many others from the Technical University of Munich, Imperial College London, INRIA, University of Oxford, OpenMined, Facebook Research, Consensys Health and Arkhn.","title":"Team"},{"location":"#publication","text":"This is the companion repository to our publication (xxx).","title":"Publication"},{"location":"#dataset","text":"We used the Paediatric Pneumonia Dataset originally created by Kermany et al. For details, see this page .","title":"Dataset"},{"location":"#disclaimer","text":"This software is a research product and is provided as is without any guarantees of functionality, security, support or compatibility. Until appropriately validated, it must not be used in any critical workflow and we assume no liability for any user action or omission.","title":"Disclaimer"},{"location":"CLI_Docs/","text":"Library Documentation Video walkthrough Documentation for the individual components This section describes what the individual components of PriMIA do. configs This folder contains the configuration files. torch contains the config.ini files which are used for configuring the training process. websetting contains files for usage with WebSocket/HTTP training over the network. Documentation for these files can be found here data This folder contains the dataset used in our publication and case study. After running make <symbolic/minimal>_server folders , a server_simulation folder appears here which holds the data for the VirtualWorker nodes. The train and test folders hold the original dataset. The two .csv files contain metadata and labels. docs This folder contains the documentation source and is not needed by the end user. figure_scripts This folder contains scripts for re-creating the figures for our publication. It is not needed by the end user. model_weights This folder does not always exist. It will be generated after a training run and stores model weights and a .csv file with the training metrics. Node This folder contains the code for setting up a PyGrid node. Documentation for how to use this can be found here site This folder contains the HTML and CSS for the documentation. It should not be changed by the end user syft This folder contains the PySyft source code. It should not be altered unless you really know what you are doing. torchlib This folder contains all the utility modules (the engine room ) for PriMIA. dataloader.py contains the CombinedLoader class which is the main dataloader for PriMIA and loads image and medical image files. It also contains various utility functions required for PriMIA's operation and ways to load both the supplied paediatric pneumonia dataset and the MNIST dataset which can be used for experimentation. dicomtools.py contains the logic for loading DICOM files. Documentation for the module can be found in the module's source. find_config.py contains the logic to run hyperparameter optimisation with Optuna. Its documentation can be found here models.py contains the models available in PriMIA, a simple CNN (called simpleconv ), a VGG-style CNN and the ResNet18 used in our publication run_websocket_server.py is a utility script to quickly run a set of WebSocket/HTTP servers to train models. It is not required for operation since servers can be run directly from the Node module. utils.py contains the entire logic for federated learning. If you are interested in the internals of PriMIA, this is where to look. DATASET_LICENSE This is the license for the dataset used, which is different from the source code license. Please read the license and use PriMIA and the data only in accordance to its terms. doc_requirements.txt This is the requirements file to build the documentation. It is normally not needed by the end user. environment_torch.yml This is the preferred way to install dependencies. See here for more information on setting up dependencies and an environment to run PriMIA. inference.py This is the entrypoint to perform (encrypted inference) with PriMIA and implements the core logic. If you are interested in the internals of encrypted inference, this is the file you are looking for. LICENSE This is the license for the source code, which is different from the dataset license. Please read the license and use PriMIA and the data only in accordance to its terms. Makefile This file contains a large amount of pre-made recipes which can make (pun intended) your life much easier. See here for how to use these recipes. mkdocs.yml This is a configuration file for the documentation. It is normally not needed by the end user README.md This contains the GitHub readme. It is not needed by the end user. requirements.txt This is the other (and not preferred) way to install dependencies. See here for more information on setting up dependencies and an environment to run PriMIA. test.py This is the entrypoint to test a trained algorithm on data which is already set up in named folders identical to the ones in our dataset. It is a convenience script to obtain model metrics and does not represent the main use-case for PriMIA. train.py This is the entrypoint to federated or local model training and contains all the logic of the training loop. If you are interested in how training in PriMIA is carried out, this is the script to look at.","title":"Library Documentation"},{"location":"CLI_Docs/#library-documentation","text":"","title":"Library Documentation"},{"location":"CLI_Docs/#video-walkthrough","text":"","title":"Video walkthrough"},{"location":"CLI_Docs/#documentation-for-the-individual-components","text":"This section describes what the individual components of PriMIA do. configs This folder contains the configuration files. torch contains the config.ini files which are used for configuring the training process. websetting contains files for usage with WebSocket/HTTP training over the network. Documentation for these files can be found here data This folder contains the dataset used in our publication and case study. After running make <symbolic/minimal>_server folders , a server_simulation folder appears here which holds the data for the VirtualWorker nodes. The train and test folders hold the original dataset. The two .csv files contain metadata and labels. docs This folder contains the documentation source and is not needed by the end user. figure_scripts This folder contains scripts for re-creating the figures for our publication. It is not needed by the end user. model_weights This folder does not always exist. It will be generated after a training run and stores model weights and a .csv file with the training metrics. Node This folder contains the code for setting up a PyGrid node. Documentation for how to use this can be found here site This folder contains the HTML and CSS for the documentation. It should not be changed by the end user syft This folder contains the PySyft source code. It should not be altered unless you really know what you are doing. torchlib This folder contains all the utility modules (the engine room ) for PriMIA. dataloader.py contains the CombinedLoader class which is the main dataloader for PriMIA and loads image and medical image files. It also contains various utility functions required for PriMIA's operation and ways to load both the supplied paediatric pneumonia dataset and the MNIST dataset which can be used for experimentation. dicomtools.py contains the logic for loading DICOM files. Documentation for the module can be found in the module's source. find_config.py contains the logic to run hyperparameter optimisation with Optuna. Its documentation can be found here models.py contains the models available in PriMIA, a simple CNN (called simpleconv ), a VGG-style CNN and the ResNet18 used in our publication run_websocket_server.py is a utility script to quickly run a set of WebSocket/HTTP servers to train models. It is not required for operation since servers can be run directly from the Node module. utils.py contains the entire logic for federated learning. If you are interested in the internals of PriMIA, this is where to look. DATASET_LICENSE This is the license for the dataset used, which is different from the source code license. Please read the license and use PriMIA and the data only in accordance to its terms. doc_requirements.txt This is the requirements file to build the documentation. It is normally not needed by the end user. environment_torch.yml This is the preferred way to install dependencies. See here for more information on setting up dependencies and an environment to run PriMIA. inference.py This is the entrypoint to perform (encrypted inference) with PriMIA and implements the core logic. If you are interested in the internals of encrypted inference, this is the file you are looking for. LICENSE This is the license for the source code, which is different from the dataset license. Please read the license and use PriMIA and the data only in accordance to its terms. Makefile This file contains a large amount of pre-made recipes which can make (pun intended) your life much easier. See here for how to use these recipes. mkdocs.yml This is a configuration file for the documentation. It is normally not needed by the end user README.md This contains the GitHub readme. It is not needed by the end user. requirements.txt This is the other (and not preferred) way to install dependencies. See here for more information on setting up dependencies and an environment to run PriMIA. test.py This is the entrypoint to test a trained algorithm on data which is already set up in named folders identical to the ones in our dataset. It is a convenience script to obtain model metrics and does not represent the main use-case for PriMIA. train.py This is the entrypoint to federated or local model training and contains all the logic of the training loop. If you are interested in how training in PriMIA is carried out, this is the script to look at.","title":"Documentation for the individual components"},{"location":"ConfigDocs/","text":"Configuration File Documentation This file contains the documentation for the configuration files, which can be found inside the configs directory. The directory has two subdirectories, torch , which contains the training-related configuration files and websetting which contains WebSocket/HTTP related configuration files. torch subdirectory The training-related configuration files can be found or placed here. A series of pre-made configuration files with self-explanatory names are available. We suggest adapting pneumonia-resnet-pretrained.ini to your purpose. This file will be required by PriMIA whenever a --config flag is required in the CLI. The structure of the file can be found below. Documentation for non self-explanatory items is included as a comment. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 [ config ] batch_size = 4 train_resolution = 224 inference_resolution = 512 test_batch_size = 1 test_interval = 1 # How often to test the model during training. # 1 means \"every epoch\" validation_split = 10 # in % epochs = 1 # How many epochs. If left empty defaults to 40 lr = 1e-4 # Initial learning rate end_lr = 1e-5 # Final learning rate after decay restarts = 0 # Warm restarting of the learning rate. 0 means no restarts beta1 = 0.5 # Adam optimiser parameter beta2 = 0.99 # Adam optimiser parameter weight_decay = 5e-4 # =L2 regularisation ; momentum = 0.5 # SGD momentum term deterministic = yes # use random seed and torch deterministic options # WARNING: this is incompatible with certain # settings and will give an appropriate warning seed = 1 # random seed log_interval = 10 # used in conjunction with visdom. # How often to log results to the visdom server optimizer = Adam # \"SGD\" or \"Adam\" differentially_private = no # use differential privacy. This feature is # experimental and not supported on complex # network architectures model = resnet - 18 # \"simpleconv\", \"vgg16\" or \"resnet-18\" pretrained = yes # Use ImageNet weights weight_classes = yes # Use class-weighted gradient descent pooling_type = max # \"max\" or \"avg\" [ augmentation ] rotation = 30 translate = 0.0 scale = 0.15 shear = 10 mixup = yes # use MixUp augmentation mixup_lambda = 0.5 # mixing parameter. Leaving it empty results # in stochastic MixUp where the parameter # gets sampled from a random uniform # distribution at every application mixup_prob = 0.9 # MixUp probability [ albumentations ] # Settings passed to albumentations clahe = yes # contrast-limited adaptive histogram equalisation overall_prob = 0.75 # overall probability of applying albumentations individual_probs = 0.2 # probabilities of the individual augmentations noise_std = 0.05 # standard deviation of the Gaussian noise noise_prob = 0.5 # probability of adding noise randomgamma = yes randombrightness = yes blur = yes elastic = yes optical_distortion = yes grid_distortion = yes grid_shuffle = no hsv = no # HSV space augmentations invert = no cutout = no shadow = no fog = yes sun_flare = no solarize = no equalize = no grid_dropout = no [ federated ] sync_every_n_batch = 2 # Synchronisation parameter. # High values make training take longer # but usually result in better performance wait_interval = 0.1 # not implemented keep_optim_dict = no # not implemented repetitions_dataset = 1 # how many times to augment/repeat the # dataset on the nodes. # Will adapt based on number of epochs weighted_averaging = yes # class-weighted federated averaging [ system ] num_threads = 16 # passed to PyTorch websetting subdirectory This contains two files, config.csv which should not be renamed but can be changed and config_inference.csv which can be renamed and is required whenever PriMIA asks for a --websockets_config file. config.csv is used by the utility script run_websocket_server.py in the torchlib directory. It is not required for normal operation of the library but rather exists as a convenience to quickly set up WebSocket/HTTP-based workers on the local system. It can be altered to change the IP addresses and ports the workers will use from their defaults. The names of the workers can also be altered, but we strongly discourage this unless you understand the consequences, as the names are used for the MNIST training example. config_inference.csv is used for remote inference. The IP addresses of the model owner, the data owner and the crypto provider as well as the ports can be set here. Please note that this is only for establishing a connection to nodes which are already running. If you want to set up nodes, this can be achieved by running the Node module with the documentation found here","title":"Configuration File Documentation"},{"location":"ConfigDocs/#configuration-file-documentation","text":"This file contains the documentation for the configuration files, which can be found inside the configs directory. The directory has two subdirectories, torch , which contains the training-related configuration files and websetting which contains WebSocket/HTTP related configuration files.","title":"Configuration File Documentation"},{"location":"ConfigDocs/#torch-subdirectory","text":"The training-related configuration files can be found or placed here. A series of pre-made configuration files with self-explanatory names are available. We suggest adapting pneumonia-resnet-pretrained.ini to your purpose. This file will be required by PriMIA whenever a --config flag is required in the CLI. The structure of the file can be found below. Documentation for non self-explanatory items is included as a comment. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 [ config ] batch_size = 4 train_resolution = 224 inference_resolution = 512 test_batch_size = 1 test_interval = 1 # How often to test the model during training. # 1 means \"every epoch\" validation_split = 10 # in % epochs = 1 # How many epochs. If left empty defaults to 40 lr = 1e-4 # Initial learning rate end_lr = 1e-5 # Final learning rate after decay restarts = 0 # Warm restarting of the learning rate. 0 means no restarts beta1 = 0.5 # Adam optimiser parameter beta2 = 0.99 # Adam optimiser parameter weight_decay = 5e-4 # =L2 regularisation ; momentum = 0.5 # SGD momentum term deterministic = yes # use random seed and torch deterministic options # WARNING: this is incompatible with certain # settings and will give an appropriate warning seed = 1 # random seed log_interval = 10 # used in conjunction with visdom. # How often to log results to the visdom server optimizer = Adam # \"SGD\" or \"Adam\" differentially_private = no # use differential privacy. This feature is # experimental and not supported on complex # network architectures model = resnet - 18 # \"simpleconv\", \"vgg16\" or \"resnet-18\" pretrained = yes # Use ImageNet weights weight_classes = yes # Use class-weighted gradient descent pooling_type = max # \"max\" or \"avg\" [ augmentation ] rotation = 30 translate = 0.0 scale = 0.15 shear = 10 mixup = yes # use MixUp augmentation mixup_lambda = 0.5 # mixing parameter. Leaving it empty results # in stochastic MixUp where the parameter # gets sampled from a random uniform # distribution at every application mixup_prob = 0.9 # MixUp probability [ albumentations ] # Settings passed to albumentations clahe = yes # contrast-limited adaptive histogram equalisation overall_prob = 0.75 # overall probability of applying albumentations individual_probs = 0.2 # probabilities of the individual augmentations noise_std = 0.05 # standard deviation of the Gaussian noise noise_prob = 0.5 # probability of adding noise randomgamma = yes randombrightness = yes blur = yes elastic = yes optical_distortion = yes grid_distortion = yes grid_shuffle = no hsv = no # HSV space augmentations invert = no cutout = no shadow = no fog = yes sun_flare = no solarize = no equalize = no grid_dropout = no [ federated ] sync_every_n_batch = 2 # Synchronisation parameter. # High values make training take longer # but usually result in better performance wait_interval = 0.1 # not implemented keep_optim_dict = no # not implemented repetitions_dataset = 1 # how many times to augment/repeat the # dataset on the nodes. # Will adapt based on number of epochs weighted_averaging = yes # class-weighted federated averaging [ system ] num_threads = 16 # passed to PyTorch","title":"torch subdirectory"},{"location":"ConfigDocs/#websetting-subdirectory","text":"This contains two files, config.csv which should not be renamed but can be changed and config_inference.csv which can be renamed and is required whenever PriMIA asks for a --websockets_config file. config.csv is used by the utility script run_websocket_server.py in the torchlib directory. It is not required for normal operation of the library but rather exists as a convenience to quickly set up WebSocket/HTTP-based workers on the local system. It can be altered to change the IP addresses and ports the workers will use from their defaults. The names of the workers can also be altered, but we strongly discourage this unless you understand the consequences, as the names are used for the MNIST training example. config_inference.csv is used for remote inference. The IP addresses of the model owner, the data owner and the crypto provider as well as the ports can be set here. Please note that this is only for establishing a connection to nodes which are already running. If you want to set up nodes, this can be achieved by running the Node module with the documentation found here","title":"websetting subdirectory"},{"location":"Dataset_Description/","text":"Dataset Description The dataset in this repository is being re-used under the license terms from the CoronaHack Chest X-Ray Dataset on Kaggle and modified as indicated in Dataset_Description.md . Original citation for the majority of the images: https://data.mendeley.com/datasets/rscbjbr9sj/2 This work is licensed under a Creative Commons Attribution 4.0 International License . The following modifications were made to create a dataset of frontal chest X-Rays of children and adolescents: All adult images (based on ossification status and/or degenerative changes to the spine) were removed. Example: All non frontal (i.e. not PA or AP) images were removed. Example: All CT-images were removed. Example: All non-grayscale images were removed. Example: All images considered of non-diagnostic quality were removed. Example: The final training set consists of 5163 images, the test set of 624 images. The original metadata file was modified to represent the new dataset. Labels were encoded as follows: Label Description 0 Normal 1 Bacterial Pneumonia 2 Viral Pneumonia The original metadata file is data/Chest_xray_Corona_Metadata.csv and the new one is data/Labels.csv .","title":"Dataset Description"},{"location":"Dataset_Description/#dataset-description","text":"The dataset in this repository is being re-used under the license terms from the CoronaHack Chest X-Ray Dataset on Kaggle and modified as indicated in Dataset_Description.md . Original citation for the majority of the images: https://data.mendeley.com/datasets/rscbjbr9sj/2 This work is licensed under a Creative Commons Attribution 4.0 International License . The following modifications were made to create a dataset of frontal chest X-Rays of children and adolescents: All adult images (based on ossification status and/or degenerative changes to the spine) were removed. Example: All non frontal (i.e. not PA or AP) images were removed. Example: All CT-images were removed. Example: All non-grayscale images were removed. Example: All images considered of non-diagnostic quality were removed. Example: The final training set consists of 5163 images, the test set of 624 images. The original metadata file was modified to represent the new dataset. Labels were encoded as follows: Label Description 0 Normal 1 Bacterial Pneumonia 2 Viral Pneumonia The original metadata file is data/Chest_xray_Corona_Metadata.csv and the new one is data/Labels.csv .","title":"Dataset Description"},{"location":"HowTo/","text":"How-To Guides Here you can find a collection of recipes for various tasks and settings you might want to try out. What do you want to do? 1. Dependencies and Environment Create a conda environment and install all dependencies to run our code and reproduce our results: Create a new conda environment with python 3.7.1. Other pythons are not supported! Run make install to recreate the environment make update can be used to update the conda environment from the .yml file. The environment will be called torch4p Disclaimer: We have only tested our code on Ubuntu 18.04 and 20.04. We cannot guarantee compatibility with any other operating system. macOS users: PriMIA should work on macOS, however only using pip as described below Use pip to set up an environment: We discourage this method and do not support it, so proceed at your own risk Make a virtual environment using the tool of your choice and using python 3.7.1. Other pythons are not supported! Run pip install -r requirements.txt to install the basic requirements After these have installed, run pip install -U syft==0.2.9 to install PySyft pip will complain (quite loudly and in red as of September 2020) about inconsistencies with torchdp . These can be ignored Clean up everything and restore the environment to its default state: Run make clean_all . Please be careful when running this, as it DELETES folders, including the model_weights folder which perhaps stores your training weights! For a detailed list of what this command destroys, check the Makefile under Cleanup . 2. Work with the Paediatric Pneumonia Dataset Distribute the data to individual worker folders: Run make server_folders . This will actually copy the files to data/server_simulation/worker<i> . It can be useful if you want to use the data on remote machines instead of locally Run make symbolic_server_folders if you intend to work locally only. This creates symbolic links, saves a lot of space and is faster Run make minimal_server_folders to create a minimal dataset of 4 images (this can be modified in the Makefile ) per worker (times the repetitions_dataset parameter from the config.ini file) for quickly trying out something after e.g. making changes to the code. 3. Work with the MNIST dataset This does not happen from the Makefile but rather is passed as a flag to the training scripts. 4. Training using VirtualWorkers Train using VirtualWorkers using the Paediatric Pneumonia dataset (quick way): Run make symbolic_server_folders to randomly split the Paediatric Pneumonia Dataset into three worker folders and a validation set. You can also run make minimal_server_folders if you are in a real hurry, but results will be predictably poor. Run make federated_secure to train a model using federated learning with secure aggregation. make federated_insecure can be used to suppress secure aggregation The model weights and a .csv file with metadata will be saved under model_weights Train using VirtualWorkers using the Paediatric Pneumonia dataset (slow way): Make whichever modifications you need to the configuration file (documentation here ) Run python train.py --config <path/to/your/config.ini> --train_federated --data_dir data/server_simulation Pass the --unencrypted_aggregation flag to suppress secure aggregation. Train on your own paediatric pneumonia data: pass --data_dir <path/to/your/data> to the CLI 5. Training using PyGrid Nodes Set up PyGrid Nodes on your local machine and run training with them Run make gridnode . This assumes you are using the Paediatric Pneumonia Dataset and the pre-made pneumonia-resnet-pretrained.ini file and is a convenience function. Make adjustments to the Makefile or directly run the following if you require more flexibility: python torchlib/run_websocket_server.py --data_dir data/server_simulation --config <path/to/your/config.ini> Run make federated_gridnode_secure to train on the GridNodes with secure aggregation or make federated_gridnode_insecure to eschew secure aggregation Set up a PyGrid Node on a local or remote server for federated training Run python -m Node --id <desired id> --port <desired port> --data_dir <path/to/data> --config <path/to/config.ini> . The configuration file must be identical on all remote servers and the central server. The name of the node, the IP address and the port must be changed in websetting/config.csv When training, the training coordinator/ central server must pass the --websockets flag to train.py which will read the settings from websetting/config.csv and configure the connections automatically. Sidenote: The number of workers can be changed by omitting workers from the configuration csv file. 6. Run training locally using GPUs Run make local . Alternatively, run python train.py --config <path/to/your/config.ini> --data_dir <path/to/data> --cuda . Note that macOS has no CUDA support. In this case, --cuda will do nothing. It can also be omitted if training on CPU is desired. 7. Miscellaneous Training If you want to adapt PriMIA to another use-case altogether, go here Monitor your training with Visdom From the command line, run visdom to start a visdom server. It will be located on localhost:xxxx . Navigate to this page with your browser. Add the --visdom flag to train.py For more information on Visdom, see here . Scroll down to see configuration options, e.g. port selection or authentication for Visdom and many tutorials! Use MNIST, VGG16 etc. These are handled using command line arguments. --data dir mnist will use MNIST from torchvision . The model can be switched in the configuration file. Check this page for details. Run a hyperparameter optimisation trial Run python torchlib/find_config.py . This assumes the system is set up for training (as described above). PriMIA uses Optuna . The system defaults to local training. If VirtualWorkers are required, pass the --federated flag. If PyGrid nodes are running, you can pass --websockets (which will be passed on to train.py ). A database file can be specified here, otherwise a default SQLite file will be used. Results can be visualised running the script with the --visualize flag, which will read the database file and open an Optuna server to show the results The results of the hyperparameter run will be located inside model_weights . If running many trials, make sure you have enough space available since this folder will become very large. Differential privacy PriMIA includes bindings for the torchdp library (now called Opacus ). Differential privacy is only implemented for simple models at the moment and is in an experimental stage. 8. Inference Run inference with VirtualWorkers Put data to classify in a directory Have a trained model ready (in .pt format) Run python inference.py --data_dir <path/to/data> --model_weights <path/to/model> --encrypted_inference . The Makefile also provides some premade recipes which need to be adapted to your data and models. CAUTION: Encrypted inference is extremely resource intensive and can cause your computer to become unresponsive or the process to be killed by your operating system. Omit the --encrypted_inference flag to perform regular remote inference On compatible systems, inference can be accelerated with --cuda Do not confuse inference with using the test.py file. This is a convenience script that will only work with the pneumonia dataset used in our publication. Run inference over the network If the --websockets_config flag is passed alongside the path to a configuration.ini file (a template can be found in configs/websetting ), inference will be performed over the network. The ports and IP addresses must match the ports and IP addresses of your machines. This requires PyGrid nodes to be set up as a data owner, a model owner and a crypto provider. The Makefile provides some templates for this. If you want to simulate this process locally, you can run make inference_setup in one terminal, then run inference.py in a different terminal. For best results, you should pass a mean_std_file for inference, which contains the mean and standard deviation of the training data which is used for re-scaling the incoming data and is generated automatically during the training process. If this is omitted, sensible defaults are used. Encrypted inference over the network is non-trivial, since the underlying WebSocket implementation has an issue where kernel TCP buffers can overflow (see issue here ). Provided you really know what you are doing, you can tune the buffers using this guide . If you experience lag, delays or performance degradation, this is likely a problem with either your network settings or hardware. PriMIA does not interact directly with any networking layer. Alternatively, we provide the option of using HTTP exclusively for inference. This is slightly slower (as HTTP is not full duplex) and requires more I/O as it uses base-64 encoding. It is rock-stable though and can be enabled with the --http_protocol flag. TLS is handled by PyGrid, not PriMIA. If you have certificates and want to use WSS or HTTPS, these need to be loaded onto the Nodes manually. Furthermore, the Nodes produce a warning related to the secret key, which should not be left at its default setting for security purposes, but passed as an environment variable. More info can be found here . Encrypted inference is very resource and I/O intensive.","title":"How-To Guides"},{"location":"HowTo/#how-to-guides","text":"Here you can find a collection of recipes for various tasks and settings you might want to try out.","title":"How-To Guides"},{"location":"HowTo/#what-do-you-want-to-do","text":"","title":"What do you want to do?"},{"location":"HowTo/#1-dependencies-and-environment","text":"Create a conda environment and install all dependencies to run our code and reproduce our results: Create a new conda environment with python 3.7.1. Other pythons are not supported! Run make install to recreate the environment make update can be used to update the conda environment from the .yml file. The environment will be called torch4p Disclaimer: We have only tested our code on Ubuntu 18.04 and 20.04. We cannot guarantee compatibility with any other operating system. macOS users: PriMIA should work on macOS, however only using pip as described below Use pip to set up an environment: We discourage this method and do not support it, so proceed at your own risk Make a virtual environment using the tool of your choice and using python 3.7.1. Other pythons are not supported! Run pip install -r requirements.txt to install the basic requirements After these have installed, run pip install -U syft==0.2.9 to install PySyft pip will complain (quite loudly and in red as of September 2020) about inconsistencies with torchdp . These can be ignored Clean up everything and restore the environment to its default state: Run make clean_all . Please be careful when running this, as it DELETES folders, including the model_weights folder which perhaps stores your training weights! For a detailed list of what this command destroys, check the Makefile under Cleanup .","title":"1. Dependencies and Environment"},{"location":"HowTo/#2-work-with-the-paediatric-pneumonia-dataset","text":"Distribute the data to individual worker folders: Run make server_folders . This will actually copy the files to data/server_simulation/worker<i> . It can be useful if you want to use the data on remote machines instead of locally Run make symbolic_server_folders if you intend to work locally only. This creates symbolic links, saves a lot of space and is faster Run make minimal_server_folders to create a minimal dataset of 4 images (this can be modified in the Makefile ) per worker (times the repetitions_dataset parameter from the config.ini file) for quickly trying out something after e.g. making changes to the code.","title":"2. Work with the Paediatric Pneumonia Dataset"},{"location":"HowTo/#3-work-with-the-mnist-dataset","text":"This does not happen from the Makefile but rather is passed as a flag to the training scripts.","title":"3. Work with the MNIST dataset"},{"location":"HowTo/#4-training-using-virtualworkers","text":"Train using VirtualWorkers using the Paediatric Pneumonia dataset (quick way): Run make symbolic_server_folders to randomly split the Paediatric Pneumonia Dataset into three worker folders and a validation set. You can also run make minimal_server_folders if you are in a real hurry, but results will be predictably poor. Run make federated_secure to train a model using federated learning with secure aggregation. make federated_insecure can be used to suppress secure aggregation The model weights and a .csv file with metadata will be saved under model_weights Train using VirtualWorkers using the Paediatric Pneumonia dataset (slow way): Make whichever modifications you need to the configuration file (documentation here ) Run python train.py --config <path/to/your/config.ini> --train_federated --data_dir data/server_simulation Pass the --unencrypted_aggregation flag to suppress secure aggregation. Train on your own paediatric pneumonia data: pass --data_dir <path/to/your/data> to the CLI","title":"4. Training using VirtualWorkers"},{"location":"HowTo/#5-training-using-pygrid-nodes","text":"Set up PyGrid Nodes on your local machine and run training with them Run make gridnode . This assumes you are using the Paediatric Pneumonia Dataset and the pre-made pneumonia-resnet-pretrained.ini file and is a convenience function. Make adjustments to the Makefile or directly run the following if you require more flexibility: python torchlib/run_websocket_server.py --data_dir data/server_simulation --config <path/to/your/config.ini> Run make federated_gridnode_secure to train on the GridNodes with secure aggregation or make federated_gridnode_insecure to eschew secure aggregation Set up a PyGrid Node on a local or remote server for federated training Run python -m Node --id <desired id> --port <desired port> --data_dir <path/to/data> --config <path/to/config.ini> . The configuration file must be identical on all remote servers and the central server. The name of the node, the IP address and the port must be changed in websetting/config.csv When training, the training coordinator/ central server must pass the --websockets flag to train.py which will read the settings from websetting/config.csv and configure the connections automatically. Sidenote: The number of workers can be changed by omitting workers from the configuration csv file.","title":"5. Training using PyGrid Nodes"},{"location":"HowTo/#6-run-training-locally-using-gpus","text":"Run make local . Alternatively, run python train.py --config <path/to/your/config.ini> --data_dir <path/to/data> --cuda . Note that macOS has no CUDA support. In this case, --cuda will do nothing. It can also be omitted if training on CPU is desired.","title":"6. Run training locally using GPUs"},{"location":"HowTo/#7-miscellaneous-training","text":"If you want to adapt PriMIA to another use-case altogether, go here Monitor your training with Visdom From the command line, run visdom to start a visdom server. It will be located on localhost:xxxx . Navigate to this page with your browser. Add the --visdom flag to train.py For more information on Visdom, see here . Scroll down to see configuration options, e.g. port selection or authentication for Visdom and many tutorials! Use MNIST, VGG16 etc. These are handled using command line arguments. --data dir mnist will use MNIST from torchvision . The model can be switched in the configuration file. Check this page for details. Run a hyperparameter optimisation trial Run python torchlib/find_config.py . This assumes the system is set up for training (as described above). PriMIA uses Optuna . The system defaults to local training. If VirtualWorkers are required, pass the --federated flag. If PyGrid nodes are running, you can pass --websockets (which will be passed on to train.py ). A database file can be specified here, otherwise a default SQLite file will be used. Results can be visualised running the script with the --visualize flag, which will read the database file and open an Optuna server to show the results The results of the hyperparameter run will be located inside model_weights . If running many trials, make sure you have enough space available since this folder will become very large. Differential privacy PriMIA includes bindings for the torchdp library (now called Opacus ). Differential privacy is only implemented for simple models at the moment and is in an experimental stage.","title":"7. Miscellaneous Training"},{"location":"HowTo/#8-inference","text":"Run inference with VirtualWorkers Put data to classify in a directory Have a trained model ready (in .pt format) Run python inference.py --data_dir <path/to/data> --model_weights <path/to/model> --encrypted_inference . The Makefile also provides some premade recipes which need to be adapted to your data and models. CAUTION: Encrypted inference is extremely resource intensive and can cause your computer to become unresponsive or the process to be killed by your operating system. Omit the --encrypted_inference flag to perform regular remote inference On compatible systems, inference can be accelerated with --cuda Do not confuse inference with using the test.py file. This is a convenience script that will only work with the pneumonia dataset used in our publication. Run inference over the network If the --websockets_config flag is passed alongside the path to a configuration.ini file (a template can be found in configs/websetting ), inference will be performed over the network. The ports and IP addresses must match the ports and IP addresses of your machines. This requires PyGrid nodes to be set up as a data owner, a model owner and a crypto provider. The Makefile provides some templates for this. If you want to simulate this process locally, you can run make inference_setup in one terminal, then run inference.py in a different terminal. For best results, you should pass a mean_std_file for inference, which contains the mean and standard deviation of the training data which is used for re-scaling the incoming data and is generated automatically during the training process. If this is omitted, sensible defaults are used. Encrypted inference over the network is non-trivial, since the underlying WebSocket implementation has an issue where kernel TCP buffers can overflow (see issue here ). Provided you really know what you are doing, you can tune the buffers using this guide . If you experience lag, delays or performance degradation, this is likely a problem with either your network settings or hardware. PriMIA does not interact directly with any networking layer. Alternatively, we provide the option of using HTTP exclusively for inference. This is slightly slower (as HTTP is not full duplex) and requires more I/O as it uses base-64 encoding. It is rock-stable though and can be enabled with the --http_protocol flag. TLS is handled by PyGrid, not PriMIA. If you have certificates and want to use WSS or HTTPS, these need to be loaded onto the Nodes manually. Furthermore, the Nodes produce a warning related to the secret key, which should not be left at its default setting for security purposes, but passed as an environment variable. More info can be found here . Encrypted inference is very resource and I/O intensive.","title":"8. Inference"},{"location":"HowToMod/","text":"Contributing to or modifying PriMIA PriMIA is designed as a generic library. If you want to use our framework to train on different data (e.g. a different number of classes) or on another task altogether (segmentation instead of classification), here are some pointers to get you started. General considerations In general, if you are interested in adapting PriMIA to a different use case, please get in touch with us and join the OpenMined team! We are an open, diverse and welcoming community and appreciate anyone who wants to get involved! If you want to switch out the network architecture ... consider using one of the networks provided, which are suitable for distributed systems. Large networks (like ResNet50) are compatible, but might be impractical to use due to the I/O overhead. That said, to include a new network, modify torchlib/models.py and adapt the training loop in train.py using standard PyTorch practices. If you want to modify the data used ... you need to change the dataloader used, which can be found in torchlib/dataloader.py for a dataloader suitable to your task. You will probably also need to modify the loss function, which can be found in torchlib/utils.py If you want to use similar data with minor modifications to the training task ... you can probably get by with minor modifications to the training loop in train.py and potentially the dataloader and loss function as discussed above. If you want to port PriMIA to PySyft 0.3.0 ... get in touch with us! We are happy to support you. If you want to port PriMIA to TensorFlow or JAX ... definitely get in touch with us! We'd be very excited! If you find a bug or want to suggest a feature ... open a GitHub issue and get in touch with us on the OpenMined Slack! Hint: we have a PriMIA logo next to our names :) If you like our work ... spread the word! Not just about us, but about privacy-preserving machine learning in general!","title":"Contributing to or modifying PriMIA"},{"location":"HowToMod/#contributing-to-or-modifying-primia","text":"PriMIA is designed as a generic library. If you want to use our framework to train on different data (e.g. a different number of classes) or on another task altogether (segmentation instead of classification), here are some pointers to get you started.","title":"Contributing to or modifying PriMIA"},{"location":"HowToMod/#general-considerations","text":"In general, if you are interested in adapting PriMIA to a different use case, please get in touch with us and join the OpenMined team! We are an open, diverse and welcoming community and appreciate anyone who wants to get involved!","title":"General considerations"},{"location":"HowToMod/#if-you-want-to-switch-out-the-network-architecture","text":"... consider using one of the networks provided, which are suitable for distributed systems. Large networks (like ResNet50) are compatible, but might be impractical to use due to the I/O overhead. That said, to include a new network, modify torchlib/models.py and adapt the training loop in train.py using standard PyTorch practices.","title":"If you want to switch out the network architecture"},{"location":"HowToMod/#if-you-want-to-modify-the-data-used","text":"... you need to change the dataloader used, which can be found in torchlib/dataloader.py for a dataloader suitable to your task. You will probably also need to modify the loss function, which can be found in torchlib/utils.py","title":"If you want to modify the data used"},{"location":"HowToMod/#if-you-want-to-use-similar-data-with-minor-modifications-to-the-training-task","text":"... you can probably get by with minor modifications to the training loop in train.py and potentially the dataloader and loss function as discussed above.","title":"If you want to use similar data with minor modifications to the training task"},{"location":"HowToMod/#if-you-want-to-port-primia-to-pysyft-030","text":"... get in touch with us! We are happy to support you.","title":"If you want to port PriMIA to PySyft 0.3.0"},{"location":"HowToMod/#if-you-want-to-port-primia-to-tensorflow-or-jax","text":"... definitely get in touch with us! We'd be very excited!","title":"If you want to port PriMIA to TensorFlow or JAX"},{"location":"HowToMod/#if-you-find-a-bug-or-want-to-suggest-a-feature","text":"... open a GitHub issue and get in touch with us on the OpenMined Slack! Hint: we have a PriMIA logo next to our names :)","title":"If you find a bug or want to suggest a feature"},{"location":"HowToMod/#if-you-like-our-work","text":"... spread the word! Not just about us, but about privacy-preserving machine learning in general!","title":"If you like our work"}]}